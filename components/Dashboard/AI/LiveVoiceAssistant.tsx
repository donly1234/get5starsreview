import React, { useState, useRef } from 'react';
import { GoogleGenAI, Modality } from '@google/genai';

const LiveVoiceAssistant: React.FC<{ onSignup: () => void }> = ({ onSignup }) => {
  const [isActive, setIsActive] = useState(false);
  const audioContextRef = useRef<AudioContext | null>(null);

  const startSession = async () => {
    try {
      const ai = new GoogleGenAI({ apiKey: process.env.API_KEY || "" });
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setIsActive(true);
      // Voice assistant session logic implementation...
    } catch (e) {
      console.error(e);
      alert("Microphone access is required for the Voice Assistant.");
    }
  };

  return (
    <div className="p-8 bg-slate-950 text-white rounded-[40px] text-center space-y-8 shadow-2xl relative overflow-hidden">
      <div className="relative z-10 space-y-4">
        <h2 className="text-3xl font-black uppercase italic tracking-tighter leading-none">Gemini Live <br /><span className="text-emerald-500">Consultant.</span></h2>
        <p className="text-slate-400 text-sm font-medium">Speak directly to an AI expert about your ranking strategy.</p>
        <div className="flex justify-center py-6">
          <button 
            onClick={() => setIsActive(!isActive)} 
            className={`w-24 h-24 rounded-full text-3xl shadow-2xl transition-all active:scale-95 ${isActive ? 'bg-rose-500 animate-pulse' : 'bg-emerald-500'}`}
          >
            {isActive ? '‚èπ' : 'üéôÔ∏è'}
          </button>
        </div>
        {isActive && <p className="text-emerald-500 font-black uppercase text-[10px] tracking-widest animate-pulse">Assistant Listening...</p>}
      </div>
      <div className="absolute top-0 right-0 w-40 h-40 bg-emerald-500/10 blur-3xl rounded-full" />
    </div>
  );
};

export default LiveVoiceAssistant;
